{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 3859\n",
      "Total labeled entries: 1997\n",
      "Split sizes. Train: 1597; Valid: 200; Test: 200\n",
      "Duplicate TICs: 0\n",
      "Splits\n",
      "  train: 1597\n",
      "  val: 200\n",
      "  test: 200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "## Read table\n",
    "fname = 'vetting-v01'\n",
    "fpath = f'../mnt/tess/labels/{fname}.csv'\n",
    "all_table = pd.read_csv(fpath, header=0, low_memory=False).set_index('Astro ID')\n",
    "\n",
    "## Rename or drop columns\n",
    "all_table.drop(columns=['Split'])\n",
    "all_table = all_table.rename(columns={'filename': 'File', \n",
    "                                      'Period': 'Per', \n",
    "                                      'Duration': 'Dur',\n",
    "                                      'Transit_Depth': 'Depth',\n",
    "                                      'star_rad': 'SRad',\n",
    "                                      'star_rad_est': 'SRadEst',\n",
    "                                      'star_mass': 'SMass',})\n",
    "\n",
    "## Make label columns\n",
    "disps = ['e', 'p', 'n', 'b', 't', 'u', 'j']\n",
    "users = ['mk', 'ch', 'et', 'md', 'as', 'dm', 'Tansu', 'Shishir']\n",
    "for d in disps:\n",
    "    all_table[f'disp_{d}'] = 0\n",
    "\n",
    "## Set labels\n",
    "def set_labels(row):\n",
    "    a = ~row.isna()\n",
    "    if row['Final'] == 'i':\n",
    "        # skip objects labeled as \"inside the star\"\n",
    "        return row\n",
    "    if a['Final']:\n",
    "        row[f'disp_{row[\"Final\"][0]}'] = 1\n",
    "        row[f'disp_{row[\"Final\"][1]}'] = 1\n",
    "    else:\n",
    "        for user in users:\n",
    "            if a[user] and row[user]:\n",
    "                row[f'disp_{row[user][0]}'] += 1\n",
    "                row[f'disp_{row[user][1]}'] += 1\n",
    "\n",
    "    return row\n",
    "\n",
    "all_table = all_table.apply(set_labels, axis=1)\n",
    "\n",
    "## Only use labelled rows and skip bad rows that have NaN in specific columns\n",
    "print(f'Total entries: {len(all_table)}')\n",
    "all_table = all_table[sum(all_table[f'disp_{d}'] for d in disps) > 0]\n",
    "all_table = all_table[~all_table[['File', 'Per', 'Dur', 'Depth', 'Tmag', 'SRad', 'SRadEst', 'SMass']].isna().any(axis=1)]\n",
    "print(f'Total labeled entries: {len(all_table)}')\n",
    "\n",
    "## Train-test split\n",
    "t_train, t_test = train_test_split(all_table, test_size=0.1, random_state=42)\n",
    "t_train, t_val = train_test_split(t_train, test_size=1./9, random_state=42)\n",
    "\n",
    "## Print sizes of arrays and print duplicate counts\n",
    "print(f'Split sizes. Train: {len(t_train)}; Valid: {len(t_val)}; Test: {len(t_test)}')\n",
    "print(f'Duplicate TICs: {len(all_table.index.values) - len(set(all_table.index.values))}')\n",
    "print('Splits')\n",
    "print('  train:', len(t_train))\n",
    "print('  val:', len(t_val))\n",
    "print('  test:', len(t_test))\n",
    "\n",
    "## Check label arrays\n",
    "assert not any((t_train['disp_e'] + t_train['disp_p']+ t_train['disp_n'] + t_train['disp_b'] + t_train['disp_t'] + t_train['disp_u'] + t_train['disp_j']) == 0)\n",
    "assert not any((t_val['disp_e'] + t_val['disp_p']+ t_val['disp_n'] + t_val['disp_b'] + t_val['disp_t'] + t_val['disp_u']+ t_val['disp_j']) == 0)\n",
    "assert not any((t_test['disp_e'] + t_test['disp_p']+ t_test['disp_n'] + t_test['disp_b'] + t_test['disp_t'] + t_test['disp_u'] + t_test['disp_j']) == 0)\n",
    "\n",
    "## Save train, test, and validation csv iles\n",
    "t_train.to_csv(f'../mnt/tess/astronet/tces-{fname}-train.csv')\n",
    "t_val.to_csv(f'../mnt/tess/astronet/tces-{fname}-val.csv')\n",
    "t_test.to_csv(f'../mnt/tess/astronet/tces-{fname}-test.csv')\n",
    "all_table.to_csv(f'../mnt/tess/astronet/tces-{fname}-all.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Astro ID\n",
       "1       False\n",
       "3       False\n",
       "4       False\n",
       "5       False\n",
       "7       False\n",
       "        ...  \n",
       "3823    False\n",
       "3824    False\n",
       "3825    False\n",
       "3830    False\n",
       "3849    False\n",
       "Length: 1997, dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_table[['File', 'Per', 'Dur', 'Depth', 'Tmag', 'SRad', 'SRadEst', 'SMass']].isna().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
